# -*- coding: utf-8 -*-
"""email_spam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RQBiuTvqTiNEailR27384polUgKr6VBK
"""

from google.colab import drive

drive.mount('/content/drive')

import numpy as np  # linear algebra
import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

df = pd.read_csv("/content/drive/MyDrive/SEM7/ML_miniproject/emails.csv")
df.head(10)

df.size

print(df.isnull().sum())
print()
df.shape

df.describe()

X = df.iloc[:, 1:3001]
X

Y = df.iloc[:, -1].values
Y

train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.25)

mnb = MultinomialNB(alpha=1.9)  # alpha by default is 1. alpha must always be > 0.
# alpha is the '1' in the formula for Laplace Smoothing (P(words))
mnb.fit(train_x, train_y)
y_pred1 = mnb.predict(test_x)
print("Accuracy Score for Naive Bayes : ", accuracy_score(y_pred1, test_y))

svc = SVC(C=1.0, kernel='rbf', gamma='auto')
# C here is the regularization parameter. Here, L2 penalty is used(default). It is the inverse of the strength of regularization.
# As C increases, model overfits.
# Kernel here is the radial basis function kernel.
# gamma (only used for rbf kernel) : As gamma increases, model overfits.
svc.fit(train_x, train_y)
y_pred2 = svc.predict(test_x)
print("Accuracy Score for SVC : ", accuracy_score(y_pred2, test_y))

rfc = RandomForestClassifier(n_estimators=100, criterion='gini')
# n_estimators = No. of trees in the forest
# criterion = basis of making the decision tree split, either on gini impurity('gini'), or on infromation gain('entropy')
rfc.fit(train_x, train_y)
y_pred3 = rfc.predict(test_x)
print("Accuracy Score of Random Forest Classifier : ", accuracy_score(y_pred3, test_y))

# @title Predictions {run : "auto"}
preset1 = test_x.iloc[[1]]
preset2 = test_x.iloc[[376]]
preset3 = test_x.iloc[[928]]
a = preset2
outputvalue = svc.predict(a)
print("Prediction: \t", outputvalue)

"""# Visualisation"""

pdf = df.groupby(['Prediction']).count()
pdf.head(10)
pdf.index = ['0', '1']
pdf.plot(kind="pie", y="count", autopct='%.f')

import sklearn.metrics as metrics

print(metrics.classification_report(test_y, y_pred2))

from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score
from mlxtend.plotting import plot_confusion_matrix

cm7 = confusion_matrix(test_y, y_pred2)
fig, ax = plot_confusion_matrix(conf_mat=cm7, figsize=(6, 6), cmap=plt.cm.Greens)
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

"""# GUI"""

import tkinter as tk
from tkinter import messagebox, ttk
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

df = pd.read_csv("emails.csv")
df.head(20)

print(df.isnull().sum())
print()
df.shape

df.describe()

# df.corr()

X = df.iloc[:, 1:3001]
# X

Y = df.iloc[:, -1].values
# Y

train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.25)

mnb = MultinomialNB(alpha=1.9)
mnb.fit(train_x, train_y)
y_pred1 = mnb.predict(test_x)
print("Accuracy Score for Naive Bayes : ", accuracy_score(y_pred1, test_y))

svc = SVC(C=1.0, kernel='rbf', gamma='auto')
svc.fit(train_x, train_y)
y_pred2 = svc.predict(test_x)
print("Accuracy Score for SVC : ", accuracy_score(y_pred2, test_y))

rfc = RandomForestClassifier(n_estimators=100, criterion='gini')
rfc.fit(train_x, train_y)
y_pred3 = rfc.predict(test_x)
print("Accuracy Score of Random Forest Classifier : ", accuracy_score(y_pred3, test_y))

preset1 = test_x.iloc[[1]]
preset2 = test_x.iloc[[376]]
preset3 = test_x.iloc[[928]]

# gui
window = tk.Tk()
window.geometry("400x300+600+200")
window.configure()
window.title("Prediction Menu")

cip = tk.Label(window, text="Custom Input: ")
cip.place(x=20, y=20)
cip_var = tk.StringVar()
cip_entry = ttk.Entry(window, width=30, textvariable=cip_var)
cip_entry.place(x=150, y=20)

preset = tk.Label(window, text="Preset Input: ")
preset.place(x=20, y=130)
preset_var = tk.StringVar()
presets = ttk.Combobox(window, width=14, textvariable=preset_var, state='readonly')
presets['values'] = ("preset1", "preset2", "preset3")
presets.current(0)
presets.place(x=150, y=130)


def assign():
    inputval = preset_var.get()
    if inputval == "preset1":
        a = preset1
        outputvalue = svc.predict(a)
        submit(inputval, outputvalue)
    if inputval == "preset2":
        a = preset2
        outputvalue = svc.predict(a)
        submit(inputval, outputvalue)
    if inputval == "preset3":
        a = preset3
        outputvalue = svc.predict(a)
        submit(inputval, outputvalue)


def submit(a, b):
    messagebox.showinfo('Resulting Prediction', "Prediction of %s : %s" % (a, b))


asg = tk.Button(window, text="Submit", bg="teal", foreground="white", command=assign)
asg.place(x=170, y=250)
window.mainloop()
